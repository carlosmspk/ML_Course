In DeepLearning:
    1 - Looked Kaggle.com for a complete yet simple dataset -> Wine Quality based on chemichal measurements
    2 - Data seems usable based on correlation values. Problem can be approached in two ways: predict wine quality from 0 to 10 as a continuous result (Regression problem) or look at the integers from 0 to 10 as different classifications (Multiclass Classification Problem). This is a supervised learning problem (we know what the output should be) and https://towardsdatascience.com/types-of-neural-network-and-what-each-one-does-explained-d9b4c0ed63a1 tells me I should use Multi-Layer Perceptrons (MLP) which is the fancy term for "the original, simple, feedforward Neural Network". It works both for regression and classification.
        2.1 - Checked if sklearn (package I was using for machine learning before) is apt for building Neural Networks -> it has some models, but has very little flexibility. Will use Keras instead.
        3.1 - Searched for example on any keras MLP model for regression online -> https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/
    4 - Keras is incompatible with ARM architecture, so going back to sklearn. New example source for sklearn MLPs (Regression, in this case) -> https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html
    5 - Got model score (0.4...) which means the model is better than a "random classifier", but no idea if it is good. Looked for measurements of performance of neural networks (how to know that it is working?) -> overall consensus is that no performance metric can tell you if your model is good, only that it is "better" than some other model (the exception is if your model gets a perfect score, in which case it can't be improved and is definitely good).
    6 - A lot of the obtained values are quite similar, despite wildly different models (MLP with a 50 neurons layer vs MLP with a 500 neurons layer followed by another 100 neurons layer had practically the same score). This lead me to believe my model wasn't actually doing much. After googling for help, I realized I had forgotten to normalize the dataset. Also, our dataset is really small with only 1k examples, thus, I ought to increase our learning rate parameter.

    7 - Decided model was working as well as it could with the available data. Went to Kaggle to look for new, different data -> dataset with a bunch of pictures of indian dishes (objective is to identify which dish is which).
    8 - Just like in the previous problem, it's a multiclass classification problem, but now with computer vision. For images and visual data, Convolutional Neural Networks (CNN) work best. Problem is, sklearn doesn't have CNNs, so I found this guide on how to allow tensorflow to work on ARM chips -> https://towardsdatascience.com/setting-up-apples-new-m1-macbooks-for-machine-learning-f9c6d67d2c0f
    9 - Looked for a way to deal with png files with python -> https://machinelearningmastery.com/how-to-load-and-manipulate-images-for-deep-learning-in-python-with-pil-pillow/